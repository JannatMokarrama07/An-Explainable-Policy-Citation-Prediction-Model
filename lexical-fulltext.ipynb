{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZCrjKCTKMEVV",
    "outputId": "3fa6129e-a6c7-421b-97e0-a5e1640ba2e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__Memory Allocated (Device): 0\n",
      "__Max Memory Allocated: 0.0\n",
      "__Memory Reserved: 0.0\n",
      "__Currently used device: 0\n",
      "__CUDNN VERSION: 8500\n",
      "__Number CUDA Devices: 1\n",
      "__CUDA Device Name: NVIDIA GeForce RTX 2080 SUPER\n",
      "__CUDA Device Total Memory [GB]: _CudaDeviceProperties(name='NVIDIA GeForce RTX 2080 SUPER', major=7, minor=5, total_memory=7969MB, multi_processor_count=48)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    print('__Memory Allocated (Device):',torch.cuda.memory_allocated())\n",
    "    print('__Max Memory Allocated:',torch.cuda.max_memory_allocated()/1e6)\n",
    "    print('__Memory Reserved:',torch.cuda.memory_reserved()/1e9)\n",
    "    print('__Currently used device:', torch.cuda.current_device())\n",
    "    print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "    print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "    print('__CUDA Device Name:',torch.cuda.get_device_name(0))\n",
    "    print('__CUDA Device Total Memory [GB]:',torch.cuda.get_device_properties(0))#.total_memory/1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GuB59YncUaHT",
    "outputId": "dedf247c-a625-49a9-cae3-f946a1813852"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KM0zaK-yj_W_",
    "outputId": "f849d593-e1e3-46a0-bbdc-cc680c47ae79"
   },
   "outputs": [],
   "source": [
    "# !python --version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "T-YSeDK0lIf4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip3 install text-preprocessing\n",
    "\n",
    "# !pip3 install nltk\n",
    "# !pip3 install lexical-diversity\n",
    "#!pip3 install trunajod\n",
    "#!pip3 install lexicalrichness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "eGQVPLJIkMLR"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import ast\n",
    "import re\n",
    "import regex\n",
    "import string\n",
    "#import functools\n",
    "from functools import reduce\n",
    "import operator  \n",
    "import warnings\n",
    "\n",
    "from itertools import groupby\n",
    "from collections import OrderedDict\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from ast import literal_eval\n",
    "\n",
    "import urllib\n",
    "import requests\n",
    "import json\n",
    "import shutil\n",
    "import time\n",
    "import fnmatch\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "#import PyPaperBot\n",
    "import nltk\n",
    "import fitz\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "import pickle\n",
    "from text_preprocessing import preprocess_text\n",
    "from text_preprocessing import *\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from patsy import dmatrices\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import normaltest\n",
    "\n",
    "import pylab \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#!pip3 install sklearn_pandas\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textacy\n",
    "from textacy import text_stats as ts\n",
    "from textacy import extract\n",
    "from textacy import preprocessing\n",
    "\n",
    "import textstat  # https://pypi.org/project/textstat/\n",
    "\n",
    "#import textract  # To read .docx files\n",
    "import spacy\n",
    "import tarfile\n",
    "import TRUNAJOD.givenness\n",
    "import TRUNAJOD.ttr\n",
    "# from TRUNAJOD import surface_proxies\n",
    "from TRUNAJOD.syllabizer import Syllabizer\n",
    "\n",
    "from TRUNAJOD import surface_proxies\n",
    "from TRUNAJOD.entity_grid import EntityGrid\n",
    "from TRUNAJOD.lexico_semantic_norms import LexicoSemanticNorm\n",
    "\n",
    "from lexicalrichness import LexicalRichness\n",
    "\n",
    "from lexical_diversity import lex_div as ld # https://pypi.org/project/lexical-diversity/\n",
    "#from textacy.text_stats import basics, counts, diversity, readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/psych256lab/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /home/psych256lab/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('words')\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords as sw\n",
    "#stop_words = stopwords.words('english')\n",
    "stop_words = sw.words('english')\n",
    "\n",
    "vocab = set(w.lower() for w in nltk.corpus.words.words())\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelLoader(object):\n",
    "    \"\"\"Class to load model.\"\"\"\n",
    "    def __init__(self, model_file):\n",
    "        tar = tarfile.open(model_file, \"r:gz\")\n",
    "        self.crea_frequency = {}\n",
    "        self.infinitive_map = {}\n",
    "        self.lemmatizer = {}\n",
    "        self.spanish_lexicosemantic_norms = {}\n",
    "        self.stopwords = {}\n",
    "        self.wordnet_noun_synsets = {}\n",
    "        self.wordnet_verb_synsets = {}\n",
    "\n",
    "        for member in tar.getmembers():\n",
    "            f = tar.extractfile(member)\n",
    "            if \"crea_frequency\" in member.name:\n",
    "                self.crea_frequency = pickle.loads(f.read())\n",
    "            if \"infinitive_map\" in member.name:\n",
    "                self.infinitive_map = pickle.loads(f.read())\n",
    "            if \"lemmatizer\" in member.name:\n",
    "                self.lemmatizer = pickle.loads(f.read())\n",
    "            if \"spanish_lexicosemantic_norms\" in member.name:\n",
    "                self.spanish_lexicosemantic_norms = pickle.loads(f.read())\n",
    "            if \"stopwords\" in member.name:\n",
    "                self.stopwords = pickle.loads(f.read())\n",
    "            if \"wordnet_noun_synsets\" in member.name:\n",
    "                self.wordnet_noun_synsets = pickle.loads(f.read())\n",
    "            if \"wordnet_verb_synsets\" in member.name:\n",
    "                self.wordnet_verb_synsets = pickle.loads(f.read())\n",
    "\n",
    "\n",
    "# Load TRUNAJOD models\n",
    "model = ModelLoader(\"trunajod_models_v0.1.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Y9v6Kyhyr1-3"
   },
   "outputs": [],
   "source": [
    "# for reproducibility\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterd_articlePolicyList2 = pd.read_csv('filterd_articlePolicyList.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2301 entries, 0 to 2300\n",
      "Data columns (total 10 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   url                         2301 non-null   object \n",
      " 1   title                       2301 non-null   object \n",
      " 2   policyList                  2301 non-null   object \n",
      " 3   policyTitles                2301 non-null   object \n",
      " 4   USApolicyCitation           2301 non-null   int64  \n",
      " 5   successful_policyList       2301 non-null   object \n",
      " 6   successful_policyTitles     2301 non-null   object \n",
      " 7   articlePdf                  2301 non-null   object \n",
      " 8   total_successful_policy     2301 non-null   int64  \n",
      " 9   successfulPolicyPercentage  2301 non-null   float64\n",
      "dtypes: float64(1), int64(2), object(7)\n",
      "memory usage: 179.9+ KB\n"
     ]
    }
   ],
   "source": [
    "filterd_articlePolicyList2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterd_articlePolicyList2.set_index('url', inplace =True)\n",
    "# filterd_articlePolicyList2.at['https://doi.org/10.1001/archderm.139.3.318','articlePdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterd_articlePolicyList2.policyTitles = filterd_articlePolicyList2.policyTitles.apply(literal_eval)\n",
    "filterd_articlePolicyList2.policyList =  filterd_articlePolicyList2.policyList.apply(literal_eval)                \n",
    "filterd_articlePolicyList2.successful_policyList = filterd_articlePolicyList2.successful_policyList.apply(literal_eval)\n",
    "filterd_articlePolicyList2.successful_policyTitles = filterd_articlePolicyList2.successful_policyTitles.apply(literal_eval)\n",
    "#filterd_articlePolicyList2.articlePdf = filterd_articlePolicyList2.articlePdf.apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns =['char_count','letter_count','word_count', 'syllable_count','monosyllabcount','polysyllabcount','sentence_count',\\\n",
    "              'avg_word_length','average_sentence_length','avg_syllables_per_word',\\\n",
    "              'n_unique_words', 'n_long_words','n_difficult_words','avg_n_unique_words','avg_n_long_words','avg_n_difficult_words', \\\n",
    "              \n",
    "              'avg_noun_count','avg_verb_count','avg_adverb_count','avg_adjective_count','avg_conjunction_count','avg_adposition_count','imp_pos_ratio',\\\n",
    "              \n",
    "              'frequency_index','pos_dissimilarity','syntactic_similarity','words_before_root',\\\n",
    "            \n",
    "              \n",
    "              'lex_ttr','lex_rttr','lex_cttr','lex_maas','lex_msttr','lex_mattr','lex_hdd','lex_mtld',\\\n",
    "              'lex_vocd','lex_herdan','lex_summer','lex_dugast','lex_yulek','lex_yulei','lex_herdanvm','lex_simpsond',\n",
    "              \n",
    "              'reading_time','smog_index','flesch_reading_ease','flesch_kincaid_grade','automated_readability_index','gunning_fog','coleman_liau_index','dale_chall_readability_score','linsear_write_formula','mcalpine_eflaw'\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in new_columns:\n",
    "    #new_similarity_column = f\"{model}_sim\"\n",
    "    filterd_articlePolicyList2[column]=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filterd_articlePolicyList2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Load sentences & embeddings from disc\n",
    "with open('article_sentences.pkl', \"rb\") as fIn:\n",
    "    article_sentences = pickle.load(fIn)\n",
    "#filterd_articlePolicyList2.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doi = 'https://doi.org/10.9778/cmajo.20190026'\n",
    "\n",
    "#article_sentences[doi]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexical_analysis(index: str, text:str):\n",
    "    doc = textacy.make_spacy_doc(text, lang=\"en_core_web_sm\")\n",
    "    ts1 = ts.TextStats(doc)\n",
    "    nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"textcat\"])\n",
    "    doc1 = nlp(text)\n",
    "    \n",
    "    word_count = textstat.lexicon_count(text, removepunct=True)\n",
    "    if (word_count>499):\n",
    "    \n",
    "        filterd_articlePolicyList2.at[index,'char_count'] = textstat.char_count(text, ignore_spaces=True)\n",
    "        filterd_articlePolicyList2.at[index,'letter_count'] = textstat.letter_count(text, ignore_spaces=True)\n",
    "        filterd_articlePolicyList2.at[index,'word_count'] = word_count\n",
    "        filterd_articlePolicyList2.at[index,'syllable_count'] = textstat.syllable_count(text)\n",
    "        filterd_articlePolicyList2.at[index,'monosyllabcount'] = textstat.monosyllabcount(text)\n",
    "        filterd_articlePolicyList2.at[index,'polysyllabcount'] = textstat.polysyllabcount(text)\n",
    "\n",
    "        filterd_articlePolicyList2.at[index,'sentence_count'] = textstat.sentence_count(text)\n",
    "        filterd_articlePolicyList2.at[index,'avg_word_length'] = textstat.avg_letter_per_word(text)\n",
    "        filterd_articlePolicyList2.at[index,'average_sentence_length'] = textstat.avg_sentence_length(text)\n",
    "        filterd_articlePolicyList2.at[index,'avg_syllables_per_word'] =  textstat.avg_syllables_per_word(text)\n",
    "\n",
    "        n_unique_words = ts1.n_unique_words\n",
    "        n_long_words = ts1.n_long_words\n",
    "        n_difficult_words = textstat.difficult_words(text)\n",
    "\n",
    "        filterd_articlePolicyList2.at[index,'n_unique_words'] = float(\"{:0.3f}\".format(n_unique_words))\n",
    "        filterd_articlePolicyList2.at[index,'n_long_words'] =  float(\"{:0.3f}\".format(n_long_words))\n",
    "        filterd_articlePolicyList2.at[index,'n_difficult_words'] = float(\"{:0.3f}\".format(n_difficult_words))\n",
    "\n",
    "        filterd_articlePolicyList2.at[index,'avg_n_unique_words'] =  float(\"{:0.3f}\".format(n_unique_words/word_count))\n",
    "        filterd_articlePolicyList2.at[index,'avg_n_long_words'] =  float(\"{:0.3f}\".format(n_long_words/word_count))\n",
    "        filterd_articlePolicyList2.at[index,'avg_n_difficult_words'] =  float(\"{:0.3f}\".format(n_difficult_words/word_count))\n",
    "\n",
    "        pos_dist = surface_proxies.pos_distribution(doc1)\n",
    "\n",
    "        noun_count = pos_dist['NOUN'] #surface_proxies.noun_count(doc))\n",
    "        adjective_count = pos_dist['ADJ']\n",
    "        verb_count = pos_dist['VERB']\n",
    "        adverb_count = pos_dist['ADV']\n",
    "        adposition_count = pos_dist['ADP']\n",
    "        conjunction_count = pos_dist['CCONJ']+pos_dist['SCONJ']\n",
    "\n",
    "        filterd_articlePolicyList2.at[index,'avg_noun_count'] = float(\"{:0.3f}\".format(noun_count/word_count))\n",
    "        filterd_articlePolicyList2.at[index,'avg_adjective_count'] = float(\"{:0.3f}\".format(adjective_count/word_count))\n",
    "        filterd_articlePolicyList2.at[index,'avg_verb_count'] = float(\"{:0.3f}\".format(verb_count/word_count))\n",
    "        filterd_articlePolicyList2.at[index,'avg_adverb_count'] =  float(\"{:0.3f}\".format(adverb_count/word_count))\n",
    "        filterd_articlePolicyList2.at[index,'avg_adposition_count'] =  float(\"{:0.3f}\".format(adposition_count/word_count))\n",
    "        filterd_articlePolicyList2.at[index,'avg_conjunction_count'] =  float(\"{:0.3f}\".format(conjunction_count/word_count))\n",
    "\n",
    "        filterd_articlePolicyList2.at[index,'imp_pos_ratio'] =  float(\"{:0.3f}\".format((noun_count+adjective_count+verb_count+adverb_count) / word_count))\n",
    "\n",
    "        filterd_articlePolicyList2.at[index,'frequency_index'] =  float(\"{:0.3f}\".format(surface_proxies.frequency_index(doc1, model.crea_frequency)))\n",
    "        filterd_articlePolicyList2.at[index,'syntactic_similarity'] = float(\"{:0.3f}\".format( surface_proxies.syntactic_similarity(doc1)))\n",
    "        filterd_articlePolicyList2.at[index,'words_before_root'] = float(\"{:0.3f}\".format( surface_proxies.words_before_root(doc1,max_depth=4)))\n",
    "        filterd_articlePolicyList2.at[index,'pos_dissimilarity'] = float(\"{:0.3f}\".format( surface_proxies.pos_dissimilarity(doc1)))\n",
    "    \n",
    "#     filterd_articlePolicyList2.at[index,'word_variation_index'] =  TRUNAJOD.ttr.word_variation_index(doc1) \n",
    "   \n",
    "#     filterd_articlePolicyList2.at[index,'ttr_d_estimate'] =  TRUNAJOD.ttr.d_estimate(doc1, min_range = 35, max_range = 50, trials = 5) \n",
    "#     filterd_articlePolicyList2.at[index,'ttr_yule_k'] =  TRUNAJOD.ttr.yule_k(doc1)\n",
    "\n",
    "        lex = LexicalRichness(text)\n",
    "\n",
    "        # # Return word count.\n",
    "        # filterd_articlePolicyList2.at[index,'words'] =  lex.words\n",
    "\n",
    "        # # Return (unique) word count.\n",
    "        # filterd_articlePolicyList2.at[index,'unique_words'] =  lex.terms\n",
    "\n",
    "        # Return type-token ratio (TTR) of text.\n",
    "        filterd_articlePolicyList2.at[index,'lex_ttr'] = float(\"{:0.3f}\".format( lex.ttr))\n",
    "        # Return root type-token ratio (RTTR) of text.\n",
    "        filterd_articlePolicyList2.at[index,'lex_rttr'] =  float(\"{:0.3f}\".format(lex.rttr))\n",
    "        # Return corrected type-token ratio (CTTR) of text.\n",
    "        filterd_articlePolicyList2.at[index,'lex_cttr'] = float(\"{:0.3f}\".format( lex.cttr))\n",
    "        # Return Maas's lexical diversity measure.\n",
    "        filterd_articlePolicyList2.at[index,'lex_maas'] = float(\"{:0.3f}\".format( lex.Maas))\n",
    "        # Return hypergeometric distribution diversity (HD-D) measure.\n",
    "        filterd_articlePolicyList2.at[index,'lex_hdd'] =  float(\"{:0.3f}\".format(lex.hdd(draws=42)))\n",
    "        # Return mean segmental type-token ratio (MSTTR).\n",
    "        filterd_articlePolicyList2.at[index,'lex_msttr'] = float(\"{:0.3f}\".format( lex.msttr(segment_window=25)))\n",
    "        # Return moving average type-token ratio (MATTR).\n",
    "        filterd_articlePolicyList2.at[index,'lex_mattr'] =  float(\"{:0.3f}\".format(lex.mattr(window_size=25)))\n",
    "        # Return Measure of Textual Lexical Diversity (MTLD).\n",
    "        filterd_articlePolicyList2.at[index,'lex_mtld'] =  float(\"{:0.3f}\".format(lex.mtld(threshold=0.72)))\n",
    "        # Return voc-D measure.\n",
    "        filterd_articlePolicyList2.at[index,'lex_vocd'] = float(\"{:0.3f}\".format( lex.vocd(ntokens=50, within_sample=100, iterations=3)))\n",
    "        # Return Herdan's lexical diversity measure.\n",
    "        filterd_articlePolicyList2.at[index,'lex_herdan'] =  float(\"{:0.3f}\".format(lex.Herdan))\n",
    "        # Return Summer's lexical diversity measure.\n",
    "        filterd_articlePolicyList2.at[index,'lex_summer'] =  float(\"{:0.3f}\".format(lex.Summer))\n",
    "        # Return Dugast's lexical diversity measure.\n",
    "        filterd_articlePolicyList2.at[index,'lex_dugast'] =  float(\"{:0.3f}\".format(lex.Dugast))\n",
    "        # Return Yule's K.\n",
    "        filterd_articlePolicyList2.at[index,'lex_yulek'] =  float(\"{:0.3f}\".format(lex.yulek))\n",
    "        # Return Yule's I.\n",
    "        filterd_articlePolicyList2.at[index,'lex_yulei'] = float(\"{:0.3f}\".format( lex.yulei))\n",
    "        # Return Herdan's Vm.\n",
    "        filterd_articlePolicyList2.at[index,'lex_herdanvm'] =  float(\"{:0.3f}\".format(lex.herdanvm))\n",
    "        # Return Simpson's D.\n",
    "        filterd_articlePolicyList2.at[index,'lex_simpsond'] = float(\"{:0.3f}\".format( lex.simpsond))\n",
    "\n",
    "        # Readability\n",
    "\n",
    "        filterd_articlePolicyList2.at[index,'reading_time'] =  float(\"{:0.3f}\".format(textstat.reading_time(text, ms_per_char=14.69)))\n",
    "        filterd_articlePolicyList2.at[index,'flesch_reading_ease'] =  float(\"{:0.3f}\".format(textstat.flesch_reading_ease(text)))\n",
    "        filterd_articlePolicyList2.at[index,'flesch_kincaid_grade'] =  float(\"{:0.3f}\".format(textstat.flesch_kincaid_grade(text)))\n",
    "        filterd_articlePolicyList2.at[index,'smog_index'] =  float(\"{:0.3f}\".format(textstat.smog_index(text)))\n",
    "        filterd_articlePolicyList2.at[index,'coleman_liau_index'] =  float(\"{:0.3f}\".format(textstat.coleman_liau_index(text)))\n",
    "        filterd_articlePolicyList2.at[index,'automated_readability_index'] =  float(\"{:0.3f}\".format(textstat.automated_readability_index(text)))\n",
    "        filterd_articlePolicyList2.at[index,'dale_chall_readability_score'] =  float(\"{:0.3f}\".format(textstat.dale_chall_readability_score(text)))\n",
    "\n",
    "        filterd_articlePolicyList2.at[index,'linsear_write_formula'] = float(\"{:0.3f}\".format( textstat.linsear_write_formula(text)))\n",
    "        filterd_articlePolicyList2.at[index,'gunning_fog'] =  float(\"{:0.3f}\".format(textstat.gunning_fog(text)))\n",
    "        filterd_articlePolicyList2.at[index,'mcalpine_eflaw'] =  float(\"{:0.3f}\".format(textstat.mcalpine_eflaw(text)))\n",
    "    \n",
    "    return None\n",
    "\n",
    "#     #lexical-diversity\n",
    "    #flt = ld.flemmatize(text)\n",
    "    # print(\"no of tokens: \",len(ld.tokenize(text)))\n",
    "    # filterd_articlePolicyList2.at[index,'ttr'] =  ld.ttr(flt)\n",
    "    # filterd_articlePolicyList2.at[index,'root_ttr'] =  ld.root_ttr(flt)\n",
    "    # filterd_articlePolicyList2.at[index,'log_ttr'] =  ld.log_ttr(flt)\n",
    "    # filterd_articlePolicyList2.at[index,'maas_ttr'] =  ld.maas_ttr(flt)\n",
    "    # filterd_articlePolicyList2.at[index,'hdd'] =  ld.hdd(flt)\n",
    "    # filterd_articlePolicyList2.at[index,'msttr'] =  ld.msttr(flt,window_length=25)\n",
    "    # filterd_articlePolicyList2.at[index,'mattr'] =  ld.mattr(flt,window_length=25)\n",
    "    # filterd_articlePolicyList2.at[index,'mtld'] =  ld.mtld(flt)\n",
    "    # filterd_articlePolicyList2.at[index,'mtld_ma_wrap'] =  ld.mtld_ma_wrap(flt)\n",
    "    # filterd_articlePolicyList2.at[index,'mtld_ma_bid'] =  ld.mtld_ma_bid(flt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_token = list(string.ascii_lowercase[1:26]) +['al','mo','cox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentenceProcessing(sentence:str)->list:\n",
    "    token_list = nltk.word_tokenize(sentence.lower())\n",
    "    filtered_token_list = [token for token in token_list if token not in remove_token if token in vocab ] #\n",
    "    filtered_token_list1 = [i[0] for i in groupby(filtered_token_list)] #removes consecutive duplicate words\n",
    "    filtered_token_list2 = [token for token in filtered_token_list1 if token not in stop_words]\n",
    "    if len(filtered_token_list2)!=0 and len(filtered_token_list1)>2:\n",
    "        return filtered_token_list1\n",
    "    else:\n",
    "        return list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textProcessing(index: str):  # article is a list of sentences\n",
    "    if index in article_sentences:\n",
    "        article_sentence_list = article_sentences[index]\n",
    "        if (len(article_sentence_list)!=0):\n",
    "            tokenized_sentence_list = [sentenceProcessing(sentence) for sentence in article_sentence_list if sentence != ''] #doc.split()\n",
    "            preprocessed_article= ' '.join([TreebankWordDetokenizer().detokenize(tokenized_sentence)+'.' for tokenized_sentence in tokenized_sentence_list if len(tokenized_sentence)!=0])\n",
    "\n",
    "            lexical_analysis(index, preprocessed_article)\n",
    "    ### call function for measurements\n",
    "    \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_list = list(filterd_articlePolicyList2.index)\n",
    "# textProcessing(doi, article_sentences[doi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=[textProcessing(article) for article in article_list] # if article_list.index(article)>1337]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1339"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_list.index('https://doi.org/10.1016/s1470-2045(11)70336-9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2296"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(article_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://doi.org/10.1001/jamapediatrics.2015.3778'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_list[329]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_sentences[article_list[1339]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterd_articlePolicyList2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filterd_articlePolicyList2.loc[article_list[500]:,new_columns[0:20]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filterd_articlePolicyList2.loc[article_list[1337]:,new_columns[20:40]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filterd_articlePolicyList2.loc[doi:,new_columns[40:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2301 entries, https://doi.org/10.1001/archderm.138.12.1584 to https://doi.org/10.9778/cmajo.20190026\n",
      "Data columns (total 62 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   title                         2301 non-null   object \n",
      " 1   policyList                    2301 non-null   object \n",
      " 2   policyTitles                  2301 non-null   object \n",
      " 3   USApolicyCitation             2301 non-null   int64  \n",
      " 4   successful_policyList         2301 non-null   object \n",
      " 5   successful_policyTitles       2301 non-null   object \n",
      " 6   articlePdf                    2301 non-null   object \n",
      " 7   total_successful_policy       2301 non-null   int64  \n",
      " 8   successfulPolicyPercentage    2301 non-null   float64\n",
      " 9   char_count                    2301 non-null   float64\n",
      " 10  letter_count                  2301 non-null   float64\n",
      " 11  word_count                    2301 non-null   float64\n",
      " 12  syllable_count                2301 non-null   float64\n",
      " 13  monosyllabcount               2301 non-null   float64\n",
      " 14  polysyllabcount               2301 non-null   float64\n",
      " 15  sentence_count                2301 non-null   float64\n",
      " 16  avg_word_length               2301 non-null   float64\n",
      " 17  average_sentence_length       2301 non-null   float64\n",
      " 18  avg_syllables_per_word        2301 non-null   float64\n",
      " 19  n_unique_words                2301 non-null   float64\n",
      " 20  n_long_words                  2301 non-null   float64\n",
      " 21  n_difficult_words             2301 non-null   float64\n",
      " 22  avg_n_unique_words            2301 non-null   float64\n",
      " 23  avg_n_long_words              2301 non-null   float64\n",
      " 24  avg_n_difficult_words         2301 non-null   float64\n",
      " 25  avg_noun_count                2301 non-null   float64\n",
      " 26  avg_verb_count                2301 non-null   float64\n",
      " 27  avg_adverb_count              2301 non-null   float64\n",
      " 28  avg_adjective_count           2301 non-null   float64\n",
      " 29  avg_conjunction_count         2301 non-null   float64\n",
      " 30  avg_adposition_count          2301 non-null   float64\n",
      " 31  imp_pos_ratio                 2301 non-null   float64\n",
      " 32  frequency_index               2301 non-null   float64\n",
      " 33  pos_dissimilarity             2301 non-null   float64\n",
      " 34  syntactic_similarity          2301 non-null   float64\n",
      " 35  words_before_root             2301 non-null   float64\n",
      " 36  lex_ttr                       2301 non-null   float64\n",
      " 37  lex_rttr                      2301 non-null   float64\n",
      " 38  lex_cttr                      2301 non-null   float64\n",
      " 39  lex_maas                      2301 non-null   float64\n",
      " 40  lex_msttr                     2301 non-null   float64\n",
      " 41  lex_mattr                     2301 non-null   float64\n",
      " 42  lex_hdd                       2301 non-null   float64\n",
      " 43  lex_mtld                      2301 non-null   float64\n",
      " 44  lex_vocd                      2301 non-null   float64\n",
      " 45  lex_herdan                    2301 non-null   float64\n",
      " 46  lex_summer                    2301 non-null   float64\n",
      " 47  lex_dugast                    2301 non-null   float64\n",
      " 48  lex_yulek                     2301 non-null   float64\n",
      " 49  lex_yulei                     2301 non-null   float64\n",
      " 50  lex_herdanvm                  2301 non-null   float64\n",
      " 51  lex_simpsond                  2301 non-null   float64\n",
      " 52  reading_time                  2301 non-null   float64\n",
      " 53  smog_index                    2301 non-null   float64\n",
      " 54  flesch_reading_ease           2301 non-null   float64\n",
      " 55  flesch_kincaid_grade          2301 non-null   float64\n",
      " 56  automated_readability_index   2301 non-null   float64\n",
      " 57  gunning_fog                   2301 non-null   float64\n",
      " 58  coleman_liau_index            2301 non-null   float64\n",
      " 59  dale_chall_readability_score  2301 non-null   float64\n",
      " 60  linsear_write_formula         2301 non-null   float64\n",
      " 61  mcalpine_eflaw                2301 non-null   float64\n",
      "dtypes: float64(54), int64(2), object(6)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "filterd_articlePolicyList2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2301"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filterd_articlePolicyList2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_csv_file = filterd_articlePolicyList2[filterd_articlePolicyList2['word_count']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2271"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "#posion dist\n",
    "final_csv_file1 = final_csv_file.copy(deep = False)\n",
    "# final_csv_file1.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_csv_file1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_csv_file1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### updated tfidf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avgSimCalculation(cellValue:list)->float:\n",
    "    newValue = float(\"{:0.3f}\".format(np.mean(cellValue)))\n",
    "    return newValue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2301 entries, 0 to 2300\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   url             2301 non-null   object \n",
      " 1   tfidf_sim       2301 non-null   object \n",
      " 2   mean_tfidf_sim  2280 non-null   float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 54.1+ KB\n"
     ]
    }
   ],
   "source": [
    "updated_tfidfScores_file = pd.read_csv('updated_tfidfScores.csv', usecols =['url','tfidf_sim'], encoding = 'utf-8')\n",
    "updated_tfidfScores_file.tfidf_sim = updated_tfidfScores_file.tfidf_sim.apply(literal_eval)\n",
    "\n",
    "updated_tfidfScores_file['mean_tfidf_sim'] = updated_tfidfScores_file['tfidf_sim'].map(avgSimCalculation)\n",
    "updated_tfidfScores_file.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File with mean article-policy similarity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sim_file_columns = ['url','mean_bert_base_uncased_sim', 'mean_sentence_t5_base_sim','mean_biobert_large_cased_v11_squad_sim',\n",
    "       'mean_biobert_large_cased_sim', 'mean_biobert_base_cased_v11_sim', 'mean_biobert_v11_sim','mean_bert_large_uncased_sim',\n",
    "       'mean_all_distilroberta_v1_sim', 'mean_all_mpnet_base_v2_sim',\n",
    "       'mean_all_MiniLM_L6_v2_sim', \n",
    "       'mean_sentence_t5_xl_sim', 'mean_political_bert_sim',\n",
    "       'mean_specter_sim', 'mean_clinical_bert_sim', 'mean_legal_bert_sim',\n",
    "       'mean_scibert_sim', \n",
    "       'mean_biobert_base_cased_v12_sim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_with_meanSimScores = pd.read_csv('finalFile_with_meanSimScores.csv', usecols = mean_sim_file_columns, encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>mean_bert_base_uncased_sim</th>\n",
       "      <th>mean_bert_large_uncased_sim</th>\n",
       "      <th>mean_all_distilroberta_v1_sim</th>\n",
       "      <th>mean_all_mpnet_base_v2_sim</th>\n",
       "      <th>mean_all_MiniLM_L6_v2_sim</th>\n",
       "      <th>mean_sentence_t5_base_sim</th>\n",
       "      <th>mean_sentence_t5_xl_sim</th>\n",
       "      <th>mean_political_bert_sim</th>\n",
       "      <th>mean_specter_sim</th>\n",
       "      <th>mean_clinical_bert_sim</th>\n",
       "      <th>mean_legal_bert_sim</th>\n",
       "      <th>mean_scibert_sim</th>\n",
       "      <th>mean_biobert_large_cased_v11_squad_sim</th>\n",
       "      <th>mean_biobert_large_cased_sim</th>\n",
       "      <th>mean_biobert_v11_sim</th>\n",
       "      <th>mean_biobert_base_cased_v12_sim</th>\n",
       "      <th>mean_biobert_base_cased_v11_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://doi.org/10.1001/archderm.138.12.1584</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.579</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://doi.org/10.1001/archderm.139.3.318</td>\n",
       "      <td>0.504</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.635</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.683</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://doi.org/10.1001/archgenpsychiatry.2009...</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://doi.org/10.1001/archgenpsychiatry.2009...</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://doi.org/10.1001/archgenpsychiatry.2010...</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296</th>\n",
       "      <td>https://doi.org/10.9745/ghsp-d-18-00275</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.921</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2297</th>\n",
       "      <td>https://doi.org/10.9745/ghsp-d-19-00195</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2298</th>\n",
       "      <td>https://doi.org/10.9758/cpn.2013.11.3.107</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.709</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.781</td>\n",
       "      <td>0.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2299</th>\n",
       "      <td>https://doi.org/10.9758/cpn.2013.11.3.118</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.756</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2300</th>\n",
       "      <td>https://doi.org/10.9778/cmajo.20190026</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.770</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2301 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    url  \\\n",
       "0          https://doi.org/10.1001/archderm.138.12.1584   \n",
       "1            https://doi.org/10.1001/archderm.139.3.318   \n",
       "2     https://doi.org/10.1001/archgenpsychiatry.2009...   \n",
       "3     https://doi.org/10.1001/archgenpsychiatry.2009...   \n",
       "4     https://doi.org/10.1001/archgenpsychiatry.2010...   \n",
       "...                                                 ...   \n",
       "2296            https://doi.org/10.9745/ghsp-d-18-00275   \n",
       "2297            https://doi.org/10.9745/ghsp-d-19-00195   \n",
       "2298          https://doi.org/10.9758/cpn.2013.11.3.107   \n",
       "2299          https://doi.org/10.9758/cpn.2013.11.3.118   \n",
       "2300             https://doi.org/10.9778/cmajo.20190026   \n",
       "\n",
       "      mean_bert_base_uncased_sim  mean_bert_large_uncased_sim  \\\n",
       "0                          0.480                        0.600   \n",
       "1                          0.504                        0.585   \n",
       "2                          0.498                        0.593   \n",
       "3                          0.475                        0.572   \n",
       "4                          0.526                        0.608   \n",
       "...                          ...                          ...   \n",
       "2296                       0.531                        0.620   \n",
       "2297                       0.560                        0.640   \n",
       "2298                       0.507                        0.604   \n",
       "2299                       0.583                        0.668   \n",
       "2300                       0.533                        0.615   \n",
       "\n",
       "      mean_all_distilroberta_v1_sim  mean_all_mpnet_base_v2_sim  \\\n",
       "0                             0.151                       0.162   \n",
       "1                             0.143                       0.153   \n",
       "2                             0.163                       0.185   \n",
       "3                             0.113                       0.128   \n",
       "4                             0.183                       0.199   \n",
       "...                             ...                         ...   \n",
       "2296                          0.157                       0.167   \n",
       "2297                          0.168                       0.175   \n",
       "2298                          0.143                       0.145   \n",
       "2299                          0.244                       0.224   \n",
       "2300                          0.139                       0.151   \n",
       "\n",
       "      mean_all_MiniLM_L6_v2_sim  mean_sentence_t5_base_sim  \\\n",
       "0                         0.135                      0.743   \n",
       "1                         0.128                      0.731   \n",
       "2                         0.157                      0.735   \n",
       "3                         0.107                      0.724   \n",
       "4                         0.161                      0.739   \n",
       "...                         ...                        ...   \n",
       "2296                      0.143                      0.734   \n",
       "2297                      0.146                      0.731   \n",
       "2298                      0.106                      0.736   \n",
       "2299                      0.185                      0.756   \n",
       "2300                      0.133                      0.717   \n",
       "\n",
       "      mean_sentence_t5_xl_sim  mean_political_bert_sim  mean_specter_sim  \\\n",
       "0                       0.645                    0.579             0.649   \n",
       "1                       0.635                    0.565             0.670   \n",
       "2                       0.642                    0.557             0.687   \n",
       "3                       0.623                    0.537             0.676   \n",
       "4                       0.650                    0.594             0.708   \n",
       "...                       ...                      ...               ...   \n",
       "2296                    0.642                    0.599             0.689   \n",
       "2297                    0.641                    0.640             0.665   \n",
       "2298                    0.645                    0.593             0.670   \n",
       "2299                    0.682                    0.651             0.685   \n",
       "2300                    0.622                    0.610             0.629   \n",
       "\n",
       "      mean_clinical_bert_sim  mean_legal_bert_sim  mean_scibert_sim  \\\n",
       "0                      0.782                0.659             0.580   \n",
       "1                      0.769                0.683             0.587   \n",
       "2                      0.776                0.685             0.599   \n",
       "3                      0.753                0.681             0.602   \n",
       "4                      0.794                0.718             0.583   \n",
       "...                      ...                  ...               ...   \n",
       "2296                   0.797                0.709             0.612   \n",
       "2297                   0.816                0.748             0.638   \n",
       "2298                   0.787                0.709             0.590   \n",
       "2299                   0.828                0.764             0.650   \n",
       "2300                   0.808                0.749             0.612   \n",
       "\n",
       "      mean_biobert_large_cased_v11_squad_sim  mean_biobert_large_cased_sim  \\\n",
       "0                                      0.913                         0.791   \n",
       "1                                      0.901                         0.788   \n",
       "2                                      0.913                         0.789   \n",
       "3                                      0.903                         0.792   \n",
       "4                                      0.919                         0.817   \n",
       "...                                      ...                           ...   \n",
       "2296                                   0.921                         0.839   \n",
       "2297                                   0.928                         0.854   \n",
       "2298                                   0.917                         0.817   \n",
       "2299                                   0.924                         0.846   \n",
       "2300                                   0.923                         0.833   \n",
       "\n",
       "      mean_biobert_v11_sim  mean_biobert_base_cased_v12_sim  \\\n",
       "0                    0.723                            0.772   \n",
       "1                    0.725                            0.762   \n",
       "2                    0.733                            0.767   \n",
       "3                    0.716                            0.752   \n",
       "4                    0.744                            0.788   \n",
       "...                    ...                              ...   \n",
       "2296                 0.751                            0.797   \n",
       "2297                 0.784                            0.822   \n",
       "2298                 0.738                            0.781   \n",
       "2299                 0.795                            0.824   \n",
       "2300                 0.770                            0.810   \n",
       "\n",
       "      mean_biobert_base_cased_v11_sim  \n",
       "0                               0.763  \n",
       "1                               0.745  \n",
       "2                               0.755  \n",
       "3                               0.742  \n",
       "4                               0.776  \n",
       "...                               ...  \n",
       "2296                            0.776  \n",
       "2297                            0.801  \n",
       "2298                            0.761  \n",
       "2299                            0.807  \n",
       "2300                            0.787  \n",
       "\n",
       "[2301 rows x 18 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_with_meanSimScores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merging Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_csv_file1_columns = list(final_csv_file1.columns)\n",
    "final_csv_file1_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_tfidfScores_file1 = updated_tfidfScores_file.set_index('url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_with_meanSimScores1 = file_with_meanSimScores.set_index('url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2271\n"
     ]
    }
   ],
   "source": [
    "# merge on common index\n",
    "merged_file = pd.merge(pd.merge(final_csv_file1[[final_csv_file1_columns[3]]+final_csv_file1_columns[8:]],updated_tfidfScores_file1['mean_tfidf_sim'], left_index =True, right_index = True), file_with_meanSimScores1, left_index =True, right_index = True)\n",
    "print(len(merged_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# https://datatofish.com/check-nan-pandas-dataframe/ \n",
    "\n",
    "merged_file1 = merged_file[merged_file['successfulPolicyPercentage']>=70]\n",
    "print(merged_file1.isnull().values.any()) #merged_file1['mean_tfidf_sim'].isnull().sum()\n",
    "merged_file2 = merged_file1.copy(deep = False)\n",
    "merged_file2.dropna(inplace = True)\n",
    "print(merged_file2.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_file2.reset_index(inplace = True)\n",
    "# merged_file2.to_csv('merged_file2.csv', encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_file2 = pd.read_csv('merged_file2.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1633 entries, 0 to 1632\n",
      "Data columns (total 74 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   url                                     1633 non-null   object \n",
      " 1   USApolicyCitation                       1633 non-null   int64  \n",
      " 2   successfulPolicyPercentage              1633 non-null   float64\n",
      " 3   char_count                              1633 non-null   float64\n",
      " 4   letter_count                            1633 non-null   float64\n",
      " 5   word_count                              1633 non-null   float64\n",
      " 6   syllable_count                          1633 non-null   float64\n",
      " 7   monosyllabcount                         1633 non-null   float64\n",
      " 8   polysyllabcount                         1633 non-null   float64\n",
      " 9   sentence_count                          1633 non-null   float64\n",
      " 10  avg_word_length                         1633 non-null   float64\n",
      " 11  average_sentence_length                 1633 non-null   float64\n",
      " 12  avg_syllables_per_word                  1633 non-null   float64\n",
      " 13  n_unique_words                          1633 non-null   float64\n",
      " 14  n_long_words                            1633 non-null   float64\n",
      " 15  n_difficult_words                       1633 non-null   float64\n",
      " 16  avg_n_unique_words                      1633 non-null   float64\n",
      " 17  avg_n_long_words                        1633 non-null   float64\n",
      " 18  avg_n_difficult_words                   1633 non-null   float64\n",
      " 19  avg_noun_count                          1633 non-null   float64\n",
      " 20  avg_verb_count                          1633 non-null   float64\n",
      " 21  avg_adverb_count                        1633 non-null   float64\n",
      " 22  avg_adjective_count                     1633 non-null   float64\n",
      " 23  avg_conjunction_count                   1633 non-null   float64\n",
      " 24  avg_adposition_count                    1633 non-null   float64\n",
      " 25  imp_pos_ratio                           1633 non-null   float64\n",
      " 26  frequency_index                         1633 non-null   float64\n",
      " 27  pos_dissimilarity                       1633 non-null   float64\n",
      " 28  syntactic_similarity                    1633 non-null   float64\n",
      " 29  words_before_root                       1633 non-null   float64\n",
      " 30  lex_ttr                                 1633 non-null   float64\n",
      " 31  lex_rttr                                1633 non-null   float64\n",
      " 32  lex_cttr                                1633 non-null   float64\n",
      " 33  lex_maas                                1633 non-null   float64\n",
      " 34  lex_msttr                               1633 non-null   float64\n",
      " 35  lex_mattr                               1633 non-null   float64\n",
      " 36  lex_hdd                                 1633 non-null   float64\n",
      " 37  lex_mtld                                1633 non-null   float64\n",
      " 38  lex_vocd                                1633 non-null   float64\n",
      " 39  lex_herdan                              1633 non-null   float64\n",
      " 40  lex_summer                              1633 non-null   float64\n",
      " 41  lex_dugast                              1633 non-null   float64\n",
      " 42  lex_yulek                               1633 non-null   float64\n",
      " 43  lex_yulei                               1633 non-null   float64\n",
      " 44  lex_herdanvm                            1633 non-null   float64\n",
      " 45  lex_simpsond                            1633 non-null   float64\n",
      " 46  reading_time                            1633 non-null   float64\n",
      " 47  smog_index                              1633 non-null   float64\n",
      " 48  flesch_reading_ease                     1633 non-null   float64\n",
      " 49  flesch_kincaid_grade                    1633 non-null   float64\n",
      " 50  automated_readability_index             1633 non-null   float64\n",
      " 51  gunning_fog                             1633 non-null   float64\n",
      " 52  coleman_liau_index                      1633 non-null   float64\n",
      " 53  dale_chall_readability_score            1633 non-null   float64\n",
      " 54  linsear_write_formula                   1633 non-null   float64\n",
      " 55  mcalpine_eflaw                          1633 non-null   float64\n",
      " 56  mean_tfidf_sim                          1633 non-null   float64\n",
      " 57  mean_bert_base_uncased_sim              1633 non-null   float64\n",
      " 58  mean_bert_large_uncased_sim             1633 non-null   float64\n",
      " 59  mean_all_distilroberta_v1_sim           1633 non-null   float64\n",
      " 60  mean_all_mpnet_base_v2_sim              1633 non-null   float64\n",
      " 61  mean_all_MiniLM_L6_v2_sim               1633 non-null   float64\n",
      " 62  mean_sentence_t5_base_sim               1633 non-null   float64\n",
      " 63  mean_sentence_t5_xl_sim                 1633 non-null   float64\n",
      " 64  mean_political_bert_sim                 1633 non-null   float64\n",
      " 65  mean_specter_sim                        1633 non-null   float64\n",
      " 66  mean_clinical_bert_sim                  1633 non-null   float64\n",
      " 67  mean_legal_bert_sim                     1633 non-null   float64\n",
      " 68  mean_scibert_sim                        1633 non-null   float64\n",
      " 69  mean_biobert_large_cased_v11_squad_sim  1633 non-null   float64\n",
      " 70  mean_biobert_large_cased_sim            1633 non-null   float64\n",
      " 71  mean_biobert_v11_sim                    1633 non-null   float64\n",
      " 72  mean_biobert_base_cased_v12_sim         1633 non-null   float64\n",
      " 73  mean_biobert_base_cased_v11_sim         1633 non-null   float64\n",
      "dtypes: float64(72), int64(1), object(1)\n",
      "memory usage: 944.2+ KB\n"
     ]
    }
   ],
   "source": [
    "merged_file2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['url',\n",
       " 'mean_bert_base_uncased_sim',\n",
       " 'mean_sentence_t5_base_sim',\n",
       " 'mean_biobert_large_cased_v11_squad_sim',\n",
       " 'mean_biobert_large_cased_sim',\n",
       " 'mean_biobert_base_cased_v11_sim',\n",
       " 'mean_biobert_v11_sim',\n",
       " 'mean_bert_large_uncased_sim',\n",
       " 'mean_all_distilroberta_v1_sim',\n",
       " 'mean_all_mpnet_base_v2_sim',\n",
       " 'mean_all_MiniLM_L6_v2_sim',\n",
       " 'mean_sentence_t5_xl_sim',\n",
       " 'mean_political_bert_sim',\n",
       " 'mean_specter_sim',\n",
       " 'mean_clinical_bert_sim',\n",
       " 'mean_legal_bert_sim',\n",
       " 'mean_scibert_sim',\n",
       " 'mean_biobert_base_cased_v12_sim']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_sim_file_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean_tfidf_sim                     False\n",
       "mean_bert_large_uncased_sim        False\n",
       "mean_all_distilroberta_v1_sim      False\n",
       "mean_all_mpnet_base_v2_sim         False\n",
       "mean_all_MiniLM_L6_v2_sim          False\n",
       "mean_sentence_t5_xl_sim            False\n",
       "mean_political_bert_sim            False\n",
       "mean_specter_sim                   False\n",
       "mean_clinical_bert_sim              True\n",
       "mean_legal_bert_sim                 True\n",
       "mean_scibert_sim                   False\n",
       "mean_biobert_base_cased_v12_sim     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(merged_file2[['mean_tfidf_sim']+mean_sim_file_columns[7:]].mean()>=0.70) # excluding 'url'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 3\n"
     ]
    }
   ],
   "source": [
    "excluding_features = ['mean_tfidf_sim', 'mean_bert_large_uncased_sim', 'mean_all_distilroberta_v1_sim', 'mean_all_mpnet_base_v2_sim', 'mean_all_MiniLM_L6_v2_sim', 'mean_sentence_t5_xl_sim', 'mean_political_bert_sim','mean_specter_sim','mean_scibert_sim']+ mean_sim_file_columns[1:7]\n",
    "# including_features = ['mean_bert_base_uncased_sim','mean_sentence_t5_base_sim','mean_clinical_bert_sim','mean_legal_bert_sim','mean_biobert_large_cased_v11_squad_sim','mean_biobert_large_cased_sim','mean_biobert_v11_sim','mean_biobert_base_cased_v12_sim','mean_biobert_base_cased_v11_sim']\n",
    "including_features = ['mean_clinical_bert_sim','mean_legal_bert_sim','mean_biobert_base_cased_v12_sim']\n",
    "print(len(excluding_features), len(including_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns3 = list(set(merged_file2.columns) - set(excluding_features)-{'successfulPolicyPercentage'})\n",
    "merged_file3 = merged_file2[new_columns3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1633"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merged_file2.info()\n",
    "# m = merged_file2.reset_index()\n",
    "# m.info()\n",
    "len(merged_file3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1633 entries, 0 to 1632\n",
      "Data columns (total 58 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   lex_herdan                       1633 non-null   float64\n",
      " 1   avg_noun_count                   1633 non-null   float64\n",
      " 2   polysyllabcount                  1633 non-null   float64\n",
      " 3   avg_n_unique_words               1633 non-null   float64\n",
      " 4   frequency_index                  1633 non-null   float64\n",
      " 5   avg_adposition_count             1633 non-null   float64\n",
      " 6   mean_clinical_bert_sim           1633 non-null   float64\n",
      " 7   lex_simpsond                     1633 non-null   float64\n",
      " 8   n_long_words                     1633 non-null   float64\n",
      " 9   lex_summer                       1633 non-null   float64\n",
      " 10  pos_dissimilarity                1633 non-null   float64\n",
      " 11  lex_rttr                         1633 non-null   float64\n",
      " 12  lex_dugast                       1633 non-null   float64\n",
      " 13  letter_count                     1633 non-null   float64\n",
      " 14  mean_biobert_base_cased_v12_sim  1633 non-null   float64\n",
      " 15  avg_conjunction_count            1633 non-null   float64\n",
      " 16  USApolicyCitation                1633 non-null   int64  \n",
      " 17  lex_hdd                          1633 non-null   float64\n",
      " 18  lex_ttr                          1633 non-null   float64\n",
      " 19  dale_chall_readability_score     1633 non-null   float64\n",
      " 20  mcalpine_eflaw                   1633 non-null   float64\n",
      " 21  lex_yulei                        1633 non-null   float64\n",
      " 22  gunning_fog                      1633 non-null   float64\n",
      " 23  mean_legal_bert_sim              1633 non-null   float64\n",
      " 24  syntactic_similarity             1633 non-null   float64\n",
      " 25  smog_index                       1633 non-null   float64\n",
      " 26  lex_cttr                         1633 non-null   float64\n",
      " 27  flesch_reading_ease              1633 non-null   float64\n",
      " 28  words_before_root                1633 non-null   float64\n",
      " 29  automated_readability_index      1633 non-null   float64\n",
      " 30  word_count                       1633 non-null   float64\n",
      " 31  lex_yulek                        1633 non-null   float64\n",
      " 32  n_difficult_words                1633 non-null   float64\n",
      " 33  syllable_count                   1633 non-null   float64\n",
      " 34  coleman_liau_index               1633 non-null   float64\n",
      " 35  avg_word_length                  1633 non-null   float64\n",
      " 36  avg_adjective_count              1633 non-null   float64\n",
      " 37  char_count                       1633 non-null   float64\n",
      " 38  linsear_write_formula            1633 non-null   float64\n",
      " 39  lex_msttr                        1633 non-null   float64\n",
      " 40  avg_verb_count                   1633 non-null   float64\n",
      " 41  sentence_count                   1633 non-null   float64\n",
      " 42  imp_pos_ratio                    1633 non-null   float64\n",
      " 43  lex_vocd                         1633 non-null   float64\n",
      " 44  lex_mattr                        1633 non-null   float64\n",
      " 45  flesch_kincaid_grade             1633 non-null   float64\n",
      " 46  n_unique_words                   1633 non-null   float64\n",
      " 47  lex_herdanvm                     1633 non-null   float64\n",
      " 48  monosyllabcount                  1633 non-null   float64\n",
      " 49  reading_time                     1633 non-null   float64\n",
      " 50  avg_n_long_words                 1633 non-null   float64\n",
      " 51  avg_syllables_per_word           1633 non-null   float64\n",
      " 52  average_sentence_length          1633 non-null   float64\n",
      " 53  lex_maas                         1633 non-null   float64\n",
      " 54  avg_adverb_count                 1633 non-null   float64\n",
      " 55  lex_mtld                         1633 non-null   float64\n",
      " 56  avg_n_difficult_words            1633 non-null   float64\n",
      " 57  url                              1633 non-null   object \n",
      "dtypes: float64(56), int64(1), object(1)\n",
      "memory usage: 740.1+ KB\n"
     ]
    }
   ],
   "source": [
    "merged_file3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### merged_file2 : all features\n",
    "#### merged_file3 : similarity scores>=70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m.to_csv(\"merged_file2.csv\", encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = set(sorted(merged_file3.columns))\n",
    "# y = set(sorted(X_train.columns))\n",
    "# print(len(x)-len(y))\n",
    "# print(y-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_file4= merged_file3.set_index('url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1633 entries, https://doi.org/10.1001/archderm.138.12.1584 to https://doi.org/10.9778/cmajo.20190026\n",
      "Data columns (total 57 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   lex_herdan                       1633 non-null   float64\n",
      " 1   avg_noun_count                   1633 non-null   float64\n",
      " 2   polysyllabcount                  1633 non-null   float64\n",
      " 3   avg_n_unique_words               1633 non-null   float64\n",
      " 4   frequency_index                  1633 non-null   float64\n",
      " 5   avg_adposition_count             1633 non-null   float64\n",
      " 6   mean_clinical_bert_sim           1633 non-null   float64\n",
      " 7   lex_simpsond                     1633 non-null   float64\n",
      " 8   n_long_words                     1633 non-null   float64\n",
      " 9   lex_summer                       1633 non-null   float64\n",
      " 10  pos_dissimilarity                1633 non-null   float64\n",
      " 11  lex_rttr                         1633 non-null   float64\n",
      " 12  lex_dugast                       1633 non-null   float64\n",
      " 13  letter_count                     1633 non-null   float64\n",
      " 14  mean_biobert_base_cased_v12_sim  1633 non-null   float64\n",
      " 15  avg_conjunction_count            1633 non-null   float64\n",
      " 16  USApolicyCitation                1633 non-null   int64  \n",
      " 17  lex_hdd                          1633 non-null   float64\n",
      " 18  lex_ttr                          1633 non-null   float64\n",
      " 19  dale_chall_readability_score     1633 non-null   float64\n",
      " 20  mcalpine_eflaw                   1633 non-null   float64\n",
      " 21  lex_yulei                        1633 non-null   float64\n",
      " 22  gunning_fog                      1633 non-null   float64\n",
      " 23  mean_legal_bert_sim              1633 non-null   float64\n",
      " 24  syntactic_similarity             1633 non-null   float64\n",
      " 25  smog_index                       1633 non-null   float64\n",
      " 26  lex_cttr                         1633 non-null   float64\n",
      " 27  flesch_reading_ease              1633 non-null   float64\n",
      " 28  words_before_root                1633 non-null   float64\n",
      " 29  automated_readability_index      1633 non-null   float64\n",
      " 30  word_count                       1633 non-null   float64\n",
      " 31  lex_yulek                        1633 non-null   float64\n",
      " 32  n_difficult_words                1633 non-null   float64\n",
      " 33  syllable_count                   1633 non-null   float64\n",
      " 34  coleman_liau_index               1633 non-null   float64\n",
      " 35  avg_word_length                  1633 non-null   float64\n",
      " 36  avg_adjective_count              1633 non-null   float64\n",
      " 37  char_count                       1633 non-null   float64\n",
      " 38  linsear_write_formula            1633 non-null   float64\n",
      " 39  lex_msttr                        1633 non-null   float64\n",
      " 40  avg_verb_count                   1633 non-null   float64\n",
      " 41  sentence_count                   1633 non-null   float64\n",
      " 42  imp_pos_ratio                    1633 non-null   float64\n",
      " 43  lex_vocd                         1633 non-null   float64\n",
      " 44  lex_mattr                        1633 non-null   float64\n",
      " 45  flesch_kincaid_grade             1633 non-null   float64\n",
      " 46  n_unique_words                   1633 non-null   float64\n",
      " 47  lex_herdanvm                     1633 non-null   float64\n",
      " 48  monosyllabcount                  1633 non-null   float64\n",
      " 49  reading_time                     1633 non-null   float64\n",
      " 50  avg_n_long_words                 1633 non-null   float64\n",
      " 51  avg_syllables_per_word           1633 non-null   float64\n",
      " 52  average_sentence_length          1633 non-null   float64\n",
      " 53  lex_maas                         1633 non-null   float64\n",
      " 54  avg_adverb_count                 1633 non-null   float64\n",
      " 55  lex_mtld                         1633 non-null   float64\n",
      " 56  avg_n_difficult_words            1633 non-null   float64\n",
      "dtypes: float64(56), int64(1)\n",
      "memory usage: 804.5+ KB\n"
     ]
    }
   ],
   "source": [
    "merged_file4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "USAcitations_data= pd.read_csv(\"USAcitations.csv\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Title', 'DOI', 'Journal', 'Published on', 'Policy citation count',\n",
       "       'URL', 'Cited by source ID', 'Cited by source', 'Cited by title',\n",
       "       'Cited by date', 'Cited by type', 'Cited by subtype',\n",
       "       'Cited by country', 'Cited by URL', 'Document page',\n",
       "       'Article funder(s)', 'USAcitationCount', 'citationLag',\n",
       "       'meanCitationLag', 'minCitationLag', 'maxCitationLag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USAcitations_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 56415 entries, https://doi.org/10.1080/10459880903217895 to https://doi.org/10.1111/j.1469-7610.2010.02222.x\n",
      "Data columns (total 1 columns):\n",
      " #   Column          Non-Null Count  Dtype\n",
      "---  ------          --------------  -----\n",
      " 0   maxCitationLag  56415 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 881.5+ KB\n"
     ]
    }
   ],
   "source": [
    "USAcitations_data1 = USAcitations_data[['URL','maxCitationLag']].drop_duplicates()\n",
    "USAcitations_data1.set_index('URL', inplace =True)\n",
    "USAcitations_data1.info()\n",
    "# ['USApolicyCitation','url'] ['URL','USAcitationCount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1633\n"
     ]
    }
   ],
   "source": [
    "# merge on common index\n",
    "merged_file_wt_citationLag = pd.merge(merged_file4, USAcitations_data1, left_index =True, right_index = True)\n",
    "print(len(merged_file_wt_citationLag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1633 entries, https://doi.org/10.1001/archderm.138.12.1584 to https://doi.org/10.9778/cmajo.20190026\n",
      "Data columns (total 58 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   lex_herdan                       1633 non-null   float64\n",
      " 1   avg_noun_count                   1633 non-null   float64\n",
      " 2   polysyllabcount                  1633 non-null   float64\n",
      " 3   avg_n_unique_words               1633 non-null   float64\n",
      " 4   frequency_index                  1633 non-null   float64\n",
      " 5   avg_adposition_count             1633 non-null   float64\n",
      " 6   mean_clinical_bert_sim           1633 non-null   float64\n",
      " 7   lex_simpsond                     1633 non-null   float64\n",
      " 8   n_long_words                     1633 non-null   float64\n",
      " 9   lex_summer                       1633 non-null   float64\n",
      " 10  pos_dissimilarity                1633 non-null   float64\n",
      " 11  lex_rttr                         1633 non-null   float64\n",
      " 12  lex_dugast                       1633 non-null   float64\n",
      " 13  letter_count                     1633 non-null   float64\n",
      " 14  mean_biobert_base_cased_v12_sim  1633 non-null   float64\n",
      " 15  avg_conjunction_count            1633 non-null   float64\n",
      " 16  USApolicyCitation                1633 non-null   int64  \n",
      " 17  lex_hdd                          1633 non-null   float64\n",
      " 18  lex_ttr                          1633 non-null   float64\n",
      " 19  dale_chall_readability_score     1633 non-null   float64\n",
      " 20  mcalpine_eflaw                   1633 non-null   float64\n",
      " 21  lex_yulei                        1633 non-null   float64\n",
      " 22  gunning_fog                      1633 non-null   float64\n",
      " 23  mean_legal_bert_sim              1633 non-null   float64\n",
      " 24  syntactic_similarity             1633 non-null   float64\n",
      " 25  smog_index                       1633 non-null   float64\n",
      " 26  lex_cttr                         1633 non-null   float64\n",
      " 27  flesch_reading_ease              1633 non-null   float64\n",
      " 28  words_before_root                1633 non-null   float64\n",
      " 29  automated_readability_index      1633 non-null   float64\n",
      " 30  word_count                       1633 non-null   float64\n",
      " 31  lex_yulek                        1633 non-null   float64\n",
      " 32  n_difficult_words                1633 non-null   float64\n",
      " 33  syllable_count                   1633 non-null   float64\n",
      " 34  coleman_liau_index               1633 non-null   float64\n",
      " 35  avg_word_length                  1633 non-null   float64\n",
      " 36  avg_adjective_count              1633 non-null   float64\n",
      " 37  char_count                       1633 non-null   float64\n",
      " 38  linsear_write_formula            1633 non-null   float64\n",
      " 39  lex_msttr                        1633 non-null   float64\n",
      " 40  avg_verb_count                   1633 non-null   float64\n",
      " 41  sentence_count                   1633 non-null   float64\n",
      " 42  imp_pos_ratio                    1633 non-null   float64\n",
      " 43  lex_vocd                         1633 non-null   float64\n",
      " 44  lex_mattr                        1633 non-null   float64\n",
      " 45  flesch_kincaid_grade             1633 non-null   float64\n",
      " 46  n_unique_words                   1633 non-null   float64\n",
      " 47  lex_herdanvm                     1633 non-null   float64\n",
      " 48  monosyllabcount                  1633 non-null   float64\n",
      " 49  reading_time                     1633 non-null   float64\n",
      " 50  avg_n_long_words                 1633 non-null   float64\n",
      " 51  avg_syllables_per_word           1633 non-null   float64\n",
      " 52  average_sentence_length          1633 non-null   float64\n",
      " 53  lex_maas                         1633 non-null   float64\n",
      " 54  avg_adverb_count                 1633 non-null   float64\n",
      " 55  lex_mtld                         1633 non-null   float64\n",
      " 56  avg_n_difficult_words            1633 non-null   float64\n",
      " 57  maxCitationLag                   1633 non-null   int64  \n",
      "dtypes: float64(56), int64(2)\n",
      "memory usage: 752.7+ KB\n"
     ]
    }
   ],
   "source": [
    "merged_file_wt_citationLag.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  2.0777709736680956\n",
      "variance:  3.7494626754559133\n"
     ]
    }
   ],
   "source": [
    "print(\"mean: \", merged_file3.USApolicyCitation.mean())\n",
    "print(\"variance: \",merged_file3.USApolicyCitation.var())\n",
    "# mean< variance: overdispersion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_with_minmax_scaling = ['avg_syllables_per_word','n_long_words','lex_mtld','lex_rttr','lex_cttr','automated_readability_index','lex_yulek','flesch_reading_ease', 'mcalpine_eflaw',\n",
    "                                'flesch_kincaid_grade','polysyllabcount','word_count','syllable_count','sentence_count','char_count','words_before_root','avg_word_length','average_sentence_length',\n",
    "                                'lex_yulei','reading_time','n_difficult_words','lex_vocd','n_unique_words','lex_dugast','smog_index','gunning_fog','linsear_write_formula',\n",
    "                                'letter_count','monosyllabcount','coleman_liau_index','dale_chall_readability_score']\n",
    "len(features_with_minmax_scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_merged_file3 = merged_file3.copy(deep = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_merged_file3[features_with_minmax_scaling] = scaler.fit_transform(scaled_merged_file3[features_with_minmax_scaling])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled_merged_file3.info()\n",
    "scaled_merged_file3['avg_word_length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(new_columns3)\n",
    "# scaled_merged_file3.info()\n",
    "len(scaled_merged_file3.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_merged_file3_class = scaled_merged_file3.copy(deep = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_merged_file3_class.loc[scaled_merged_file3_class['USApolicyCitation']>1, 'USApolicyCitation'] = 0\n",
    "# df.loc[df[\"gender\"] == \"male\", \"gender\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1002\n",
       "0     631\n",
       "Name: USApolicyCitation, dtype: int64"
      ]
     },
     "execution_count": 842,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_merged_file3_class['USApolicyCitation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">per 0.675 (0.018)\n",
      ">per 0.658 (0.022)\n",
      "per: 0.6664872869143118\n",
      ">cart 0.664 (0.014)\n",
      ">cart 0.654 (0.027)\n",
      "cart: 0.6589370824741849\n",
      ">rf 0.654 (0.016)\n",
      ">rf 0.644 (0.026)\n",
      "rf: 0.6491756005960523\n",
      ">gbm 0.668 (0.018)\n",
      ">gbm 0.661 (0.031)\n",
      "gbm: 0.664349253106626\n"
     ]
    }
   ],
   "source": [
    "# explore the algorithm wrapped by RFE\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    # # lr\n",
    "    # rfe = RFE(estimator=LogisticRegression(), n_features_to_select=5)\n",
    "    # model = DecisionTreeClassifier()\n",
    "    # models['lr'] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    # perceptron\n",
    "    rfe = RFE(estimator=Perceptron(), n_features_to_select=10)\n",
    "    model = DecisionTreeClassifier()\n",
    "    models['per'] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    # cart\n",
    "    rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=10)\n",
    "    model = DecisionTreeClassifier()\n",
    "    models['cart'] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    # rf\n",
    "    rfe = RFE(estimator=RandomForestClassifier(), n_features_to_select=10)\n",
    "    model = DecisionTreeClassifier()\n",
    "    models['rf'] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    # gbm\n",
    "    rfe = RFE(estimator=GradientBoostingClassifier(), n_features_to_select=10)\n",
    "    model = DecisionTreeClassifier()\n",
    "    models['gbm'] = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "    return models\n",
    "\n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=3, random_state=1)\n",
    "    scores_pre = cross_val_score(model, X, y, scoring='precision', cv=cv, n_jobs=-1)\n",
    "    scores_re = cross_val_score(model, X, y, scoring='recall', cv=cv, n_jobs=-1)\n",
    "    return (scores_pre,scores_re)\n",
    "\n",
    "# define dataset\n",
    "X = scaled_merged_file3_class.drop(['USApolicyCitation'], axis = 1)\n",
    "y = scaled_merged_file3_class['USApolicyCitation']\n",
    "# X_train = sm.add_constant(X_train)\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    scores_pre, scores_re = evaluate_model(model, X, y)\n",
    "    \n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores_pre), std(scores_pre)))\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores_re), std(scores_re)))\n",
    "    \n",
    "    f1_score = (2*mean(scores_pre)*mean(scores_re))/(mean(scores_pre)+mean(scores_re))\n",
    "    \n",
    "    print(f'{name}: {f1_score}')\n",
    "    \n",
    "    \n",
    "    # results.append(f1_score)\n",
    "# plot model performance for comparison\n",
    "# pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(merged_file3.columns))\n",
    "sorted(list(merged_file3.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train,df_test=train_test_split(scaled_merged_file3, train_size = 0.7,random_state =1) #new_frame\n",
    "# X_train = train['mean_tfidf_sim'].values.reshape(-1, 1)\n",
    "# y_train = train.USApolicyCitation\n",
    "# X_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    }
   ],
   "source": [
    "print(len(df_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Setup the regression expression in patsy notation. We are telling patsy that BB_COUNT is our dependent variable and\n",
    "# it depends on the regression variables: DAY, DAY_OF_WEEK, MONTH, HIGH_T, LOW_T and PRECIP.\n",
    "# expr = \"\"\"USApolicyCitation ~ avg_n_long_words+avg_n_difficult_words+avg_adposition_count+pos_dissimilarity+syntactic_similarity+lex_mtld\"\"\"\n",
    "# expr = \"\"\"USApolicyCitation ~ avg_n_unique_words+char_count+letter_count+word_count+syllable_count+monosyllabcount+polysyllabcount+sentence_count+avg_word_length+average_sentence_length+avg_syllables_per_word+n_unique_words+n_long_words+n_difficult_words+avg_n_unique_words+avg_n_long_words+avg_n_difficult_words+avg_noun_count+avg_verb_count+avg_adverb_count+avg_adjective_count+avg_conjunction_count+avg_adposition_count+imp_pos_ratio+frequency_index+pos_dissimilarity+syntactic_similarity+words_before_root+lex_ttr+lex_rttr+lex_cttr+lex_maas+lex_msttr+lex_mattr+lex_hdd+lex_mtld+lex_vocd+lex_herdan+lex_summer+lex_dugast+lex_yulek+lex_yulei+lex_herdanvm+lex_simpsond+reading_time+smog_index+flesch_reading_ease+flesch_kincaid_grade+automated_readability_index+gunning_fog+coleman_liau_index+dale_chall_readability_score+linsear_write_formula+\n",
    "#  mcalpine_eflaw+linsear_write_formula\"\"\"\n",
    "\n",
    "# expr = \"\"\"USApolicyCitation ~ avg_n_unique_words+char_count+letter_count+word_count+syllable_count+monosyllabcount+polysyllabcount+sentence_count+avg_word_length+average_sentence_length+avg_syllables_per_word+n_unique_words+n_long_words+n_difficult_words+avg_n_unique_words+avg_n_long_words+avg_n_difficult_words+avg_noun_count+avg_verb_count+avg_adverb_count+avg_adjective_count+avg_conjunction_count+avg_adposition_count+imp_pos_ratio+frequency_index+pos_dissimilarity+syntactic_similarity+words_before_root+lex_ttr+lex_rttr+lex_cttr+lex_maas+lex_msttr+lex_mattr+lex_hdd+lex_mtld+lex_vocd+lex_herdan+lex_summer+lex_dugast+lex_yulek+lex_yulei+lex_herdanvm+lex_simpsond+reading_time+smog_index+flesch_reading_ease+flesch_kincaid_grade+automated_readability_index+gunning_fog+coleman_liau_index+dale_chall_readability_score+linsear_write_formula+\n",
    "  # mcalpine_eflaw+linsear_write_formula+mean_bert_base_uncased_sim+mean_bert_large_uncased_sim+mean_all_distilroberta_v1_sim+mean_all_mpnet_base_v2_sim+mean_all_MiniLM_L6_v2_sim+mean_sentence_t5_base_sim+ mean_tfidf_sim+\n",
    "  # +mean_sentence_t5_xl_sim+mean_political_bert_sim+mean_specter_sim+mean_clinical_bert_sim+mean_legal_bert_sim+mean_scibert_sim+mean_biobert_large_cased_v11_squad_sim+mean_biobert_large_cased_sim+mean_biobert_v11_sim+mean_biobert_base_cased_v12_sim+mean_biobert_base_cased_v11_sim\"\"\"\n",
    "#Set up the X and y matrices\n",
    "# expr = \"\"\"USApolicyCitation ~ avg_verb_count+linsear_write_formula+mean_specter_sim+syntactic_similarity+avg_adjective_count+avg_adposition_count+pos_dissimilarity+words_before_root\n",
    "# +avg_conjunction_count+frequency_index+mean_tfidf_sim+avg_adverb_count\"\"\"\n",
    "\n",
    "\n",
    "expr = \"\"\"USApolicyCitation ~ automated_readability_index+\n",
    "                             avg_n_unique_words+\n",
    "                             avg_syllables_per_word+\n",
    "                             avg_n_long_words+\n",
    "                             avg_n_difficult_words+\n",
    "                             avg_n_unique_words+\n",
    "                             average_sentence_length+\n",
    "                             avg_word_length+\n",
    "                             \n",
    "                             avg_noun_count+\n",
    "                             avg_verb_count+\n",
    "                             avg_adverb_count+\n",
    "                             avg_adjective_count+\n",
    "                             avg_conjunction_count+\n",
    "                             avg_adposition_count+\n",
    "                             \n",
    "                             char_count+\n",
    "                             coleman_liau_index+ \n",
    "                             \n",
    "                             dale_chall_readability_score+\n",
    "                             \n",
    "                             flesch_reading_ease+\n",
    "                             flesch_kincaid_grade+\n",
    "                             frequency_index+  \n",
    "                             \n",
    "                             gunning_fog+\n",
    "                             \n",
    "                             imp_pos_ratio+\n",
    "                             \n",
    "                             lex_ttr+\n",
    "                             lex_rttr+\n",
    "                             lex_cttr+\n",
    "                             lex_maas+\n",
    "                             lex_msttr+\n",
    "                             lex_mattr+\n",
    "                             lex_hdd+\n",
    "                             lex_mtld+\n",
    "                             lex_vocd+\n",
    "                             lex_herdan+\n",
    "                             lex_summer+\n",
    "                             lex_dugast+\n",
    "                             lex_yulek+\n",
    "                             lex_yulei+\n",
    "                             lex_herdanvm+\n",
    "                             lex_simpsond+\n",
    "                             letter_count+\n",
    "                             linsear_write_formula+\n",
    "                             \n",
    "                             mcalpine_eflaw+\n",
    "                             mean_sentence_t5_base_sim+\n",
    "                             mean_clinical_bert_sim+\n",
    "                             mean_legal_bert_sim+\n",
    "                             mean_biobert_large_cased_v11_squad_sim+\n",
    "                             mean_biobert_large_cased_sim+\n",
    "                             mean_biobert_v11_sim+\n",
    "                             mean_biobert_base_cased_v12_sim+\n",
    "                             mean_biobert_base_cased_v11_sim+\n",
    "                             monosyllabcount+\n",
    "                            \n",
    "                             n_unique_words+\n",
    "                             n_long_words+\n",
    "                             n_difficult_words+\n",
    "                            \n",
    "                             polysyllabcount+\n",
    "                             pos_dissimilarity+\n",
    "                            \n",
    "                             reading_time+\n",
    "                             \n",
    "                             sentence_count+\n",
    "                             smog_index+\n",
    "                             syntactic_similarity+\n",
    "                             syllable_count+\n",
    "                            \n",
    "                             word_count+\n",
    "                             words_before_root\n",
    "                            \n",
    "                \n",
    "                              \n",
    "                            \"\"\"\n",
    "#Set up the X and y matrices\n",
    "\n",
    "y_train, X_train = dmatrices(expr, df_train, return_type='dataframe')\n",
    "y_test, X_test = dmatrices(expr, df_test, return_type='dataframe')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = df_train.drop(['USApolicyCitation'], axis = 1)\n",
    "# X_train = sm.add_constant(X_train)\n",
    "\n",
    "# y_train = df_train['USApolicyCitation']\n",
    "\n",
    "# X_test =  df_test.drop(['USApolicyCitation'], axis = 1)\n",
    "# X_test = sm.add_constant(X_test)\n",
    "\n",
    "# y_test = df_test['USApolicyCitation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lex_herdanvm', 'avg_verb_count', 'avg_word_length', 'lex_hdd',\n",
       "       'word_count', 'flesch_kincaid_grade', 'lex_rttr',\n",
       "       'dale_chall_readability_score', 'lex_cttr', 'mcalpine_eflaw',\n",
       "       'pos_dissimilarity', 'mean_legal_bert_sim', 'avg_conjunction_count',\n",
       "       'avg_noun_count', 'frequency_index', 'n_long_words', 'avg_adverb_count',\n",
       "       'automated_readability_index', 'lex_mtld', 'lex_maas',\n",
       "       'avg_n_difficult_words', 'lex_yulek', 'flesch_reading_ease',\n",
       "       'avg_syllables_per_word', 'lex_mattr', 'polysyllabcount',\n",
       "       'syntactic_similarity', 'lex_msttr', 'mean_sentence_t5_base_sim',\n",
       "       'mean_biobert_large_cased_v11_squad_sim', 'avg_adposition_count',\n",
       "       'sentence_count', 'words_before_root', 'average_sentence_length',\n",
       "       'char_count', 'lex_yulei', 'reading_time', 'mean_biobert_v11_sim',\n",
       "       'n_difficult_words', 'lex_vocd', 'n_unique_words', 'lex_dugast',\n",
       "       'imp_pos_ratio', 'smog_index', 'mean_biobert_base_cased_v12_sim',\n",
       "       'gunning_fog', 'mean_biobert_base_cased_v11_sim', 'USApolicyCitation',\n",
       "       'linsear_write_formula', 'lex_summer', 'mean_clinical_bert_sim',\n",
       "       'mean_biobert_large_cased_sim', 'syllable_count', 'lex_ttr',\n",
       "       'avg_n_long_words', 'letter_count', 'lex_simpsond',\n",
       "       'avg_n_unique_words', 'lex_herdan', 'avg_adjective_count',\n",
       "       'monosyllabcount', 'coleman_liau_index'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 723,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_file3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_new_columns3 = set(new_columns3) -{'USApolicyCitation'}\n",
    "# print(len(new_columns3))\n",
    "# len(updated_new_columns3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Spearman's correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:\n",
      "['lex_herdanvm', 'avg_verb_count', 'avg_word_length', 'word_count', 'flesch_kincaid_grade', 'lex_rttr', 'mcalpine_eflaw', 'pos_dissimilarity', 'mean_legal_bert_sim', 'avg_conjunction_count', 'frequency_index', 'avg_noun_count', 'avg_adverb_count', 'lex_mtld', 'syntactic_similarity', 'mean_sentence_t5_base_sim', 'avg_adposition_count', 'linsear_write_formula', 'avg_adjective_count', 'words_before_root'] \n",
      "\n",
      "Total :  20\n",
      "{'lex_hdd', 'dale_chall_readability_score', 'lex_cttr', 'automated_readability_index', 'n_long_words', 'lex_maas', 'avg_n_difficult_words', 'lex_yulek', 'flesch_reading_ease', 'avg_syllables_per_word', 'lex_mattr', 'polysyllabcount', 'lex_msttr', 'mean_biobert_large_cased_v11_squad_sim', 'sentence_count', 'average_sentence_length', 'char_count', 'lex_yulei', 'reading_time', 'mean_biobert_v11_sim', 'n_difficult_words', 'lex_vocd', 'n_unique_words', 'lex_dugast', 'imp_pos_ratio', 'smog_index', 'mean_biobert_base_cased_v12_sim', 'gunning_fog', 'mean_biobert_base_cased_v11_sim', 'lex_summer', 'mean_clinical_bert_sim', 'mean_biobert_large_cased_sim', 'syllable_count', 'lex_ttr', 'avg_n_long_words', 'letter_count', 'lex_simpsond', 'avg_n_unique_words', 'lex_herdan', 'monosyllabcount', 'coleman_liau_index'}\n"
     ]
    }
   ],
   "source": [
    "correlated_features = set()\n",
    "correlation_matrix = scaled_merged_file3[updated_new_columns3].corr(method='spearman')\n",
    "\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) >= 0.7:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            correlated_features.add(colname)\n",
    "            # print(colname,\"\\n\",correlated_features)\n",
    "correlation_matrix_cols = set(correlation_matrix.columns)\n",
    "selected_features_spearmanr = list(correlation_matrix_cols-correlated_features)\n",
    "\n",
    "print(\"Selected Features:\")\n",
    "print(selected_features_spearmanr,\"\\n\\nTotal : \", len(selected_features_spearmanr))\n",
    "print(correlated_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:\n",
      "['lex_herdanvm', 'avg_verb_count', 'avg_word_length', 'word_count', 'flesch_kincaid_grade', 'lex_rttr', 'mcalpine_eflaw', 'pos_dissimilarity', 'mean_legal_bert_sim', 'avg_conjunction_count', 'frequency_index', 'avg_noun_count', 'avg_adverb_count', 'lex_mtld', 'syntactic_similarity', 'mean_sentence_t5_base_sim', 'avg_adposition_count', 'linsear_write_formula', 'avg_adjective_count', 'words_before_root'] \n",
      "\n",
      "Total :  11\n"
     ]
    }
   ],
   "source": [
    "# Calculate Spearman correlation matrix among predictors\n",
    "# keep an eye on USApolicyCitation and successfulPolicyPercentage\n",
    "\n",
    "correlation_matrix = scaled_merged_file3[updated_new_columns3].corr(method='spearman')\n",
    "\n",
    "# Set the diagonal elements (correlation with self) to zero\n",
    "np.fill_diagonal(correlation_matrix.values, 0)\n",
    "\n",
    "# Set the threshold for correlation (choose as per requirement)\n",
    "threshold = 0.7\n",
    "\n",
    "# Identify highly correlated features\n",
    "highly_correlated_features = set()\n",
    "for col in correlation_matrix.columns:\n",
    "    \n",
    "#     print(col)\n",
    "#     print(correlation_matrix[col].abs())\n",
    "          \n",
    "    correlated_cols = correlation_matrix.index[correlation_matrix[col].abs() >= threshold].tolist()\n",
    "    highly_correlated_features.update(correlated_cols)\n",
    "    \n",
    "    # print(correlated_cols)\n",
    "    # print(highly_correlated_features)\n",
    "# print(\"Highly Correlated Features:\")\n",
    "# print(highly_correlated_features)\n",
    "correlation_matrix_cols = set(correlation_matrix.columns)\n",
    "selected_features_spearmanr = list(correlation_matrix_cols-highly_correlated_features)\n",
    "\n",
    "print(\"Selected Features:\")\n",
    "print(selected_features,\"\\n\\nTotal : \", len(selected_features_spearmanr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spearman's Correlation\n",
    "def display_correlation(df):\n",
    "    r = df.corr(method=\"spearman\")\n",
    "    plt.figure(figsize=(10,6))\n",
    "    heatmap = sns.heatmap(r, vmin=-1, \n",
    "                      vmax=1, annot=True)\n",
    "    plt.title(\"Spearman Correlation\")\n",
    "    return(r)\n",
    "\n",
    "\n",
    "def display_corr_pairs(df,color=\"cyan\"):\n",
    "    s = set_title = np.vectorize(lambda ax,r,rho: ax.title.set_text(\"r = \" + \n",
    "                                        \"{:.2f}\".format(r) + \n",
    "                                        '\\n $\\\\rho$ = ' + \n",
    "                                        \"{:.2f}\".format(rho)) if ax!=None else None\n",
    "                            )      \n",
    "\n",
    "    r = display_correlation(df)\n",
    "    rho = df.corr(method=\"spearman\")\n",
    "    g = sns.PairGrid(df,corner=True)\n",
    "    g.map_diag(plt.hist,color=\"yellow\")\n",
    "    g.map_lower(sns.scatterplot,color=\"magenta\")\n",
    "    set_title(g.axes,r,rho)\n",
    "    plt.subplots_adjust(hspace = 0.6)\n",
    "    plt.show()    \n",
    "    \n",
    "display_corr_pairs(scaled_merged_file3[selected_features_spearmanr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"lexical_diversity_mltd: \",TRUNAJOD.ttr.d_estimate(doc, min_range = 35, max_range = 50, trials = 5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc(4273 tokens: \"open or its open he epidemic related to an incr...\")\n",
      "n_chars:  21467\n",
      "n_syllables:  6599\n",
      "n_monosyllable_words:  2396\n",
      "n_words:  3997\n",
      "n_unique_words:  713\n",
      "n_long_words:  1433\n",
      "no of tokens:  4273\n",
      "n_sents:  269\n",
      "\n",
      "\n",
      "flesch_kincaid_grade_level:  9.68656830913148\n",
      "automated_readability_index:  11.295732803319957\n",
      "flesch_reading_ease:  52.07977769572537\n",
      "smog_index:  12.488271264903705\n",
      "\n",
      "\n",
      "no of tokens:  5571\n",
      "ttr:  0.18739903069466882\n",
      "root_ttr:  13.98730095641165\n",
      "log_ttr:  0.805860748435703\n",
      "maas_ttr:  0.05182667264787474\n",
      "mtld:  60.832912291790876\n",
      "hdd:  0.8501844379167769\n",
      "msttr:  0.8641441441441438\n",
      "mattr:  0.8650658013341067\n",
      "mtld_ma_wrap:  65.04559325076288\n",
      "mtld_ma_bid:  64.57289505385768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nDoc(4213 tokens: \"open or its open he epidemic related to an incr...\")\\nn_chars:  21196\\nn_syllables:  6525\\nn_monosyllable_words:  2348\\nn_words:  3938\\nn_unique_words:  690\\nn_long_words:  1428\\nno of tokens:  4213\\nn_sents:  267\\n\\n\\nflesch_kincaid_grade_level:  9.713937777118371\\nautomated_readability_index:  11.295765964205486\\nflesch_reading_ease:  51.688214848884314\\nsmog_index:  12.497200199523625\\n\\n\\nno of tokens:  3937\\nttr:  0.16535433070866143\\nroot_ttr:  10.37524309552979\\nlog_ttr:  0.7826012614032555\\nmaas_ttr:  0.06046974575978705\\nmtld:  41.75758664087188\\nhdd:  0.7861842407255152\\nmsttr:  0.8201273885350322\\nmattr:  0.8163250702785934\\nmtld_ma_wrap:  44.32816865633731\\nmtld_ma_bid:  43.98230315465504'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text = (\n",
    "#     \"Many years later, as he faced the firing squad, Colonel Aureliano BuendÃ­a \"\n",
    "#      \"was to remember that distant afternoon when his father took him to discover ice. \"\n",
    "#      \"At that time Macondo was a village of twenty adobe houses, built on the bank \"\n",
    "#      \"of a river of clear water that ran along a bed of polished stones, which were \"\n",
    "#      \"white and enormous, like prehistoric eggs. The world was so recent \"\n",
    "#      \"that many things lacked names, and in order to indicate them it was necessary to point.\"\n",
    "#  )\n",
    "\n",
    "\n",
    "\n",
    "doc = textacy.make_spacy_doc(output1, lang=\"en_core_web_sm\")\n",
    "print(doc._.preview)\n",
    "\n",
    "ts1 = ts.TextStats(doc)\n",
    "print(\"n_chars: \",ts1.n_chars)\n",
    "print(\"n_syllables: \",ts1.n_syllables)\n",
    "print(\"n_monosyllable_words: \",ts1.n_monosyllable_words)\n",
    "\n",
    "print(\"n_words: \",ts1.n_words)\n",
    "print(\"n_unique_words: \",ts1.n_unique_words)\n",
    "print(\"n_long_words: \", ts1.n_long_words) #ts.basics.n_words(doc)\n",
    "print(\"no of tokens: \",len(doc)) #no of tokens\n",
    "print(\"n_sents: \",ts1.n_sents)#n_sents(doc)\n",
    "print(\"\\n\")\n",
    "#readability\n",
    "print(\"flesch_kincaid_grade_level: \", ts1.flesch_kincaid_grade_level)\n",
    "#10.922857142857143\n",
    "print(\"automated_readability_index: \",ts1.automated_readability_index)\n",
    "print(\"flesch_reading_ease: \",ts1.flesch_reading_ease)\n",
    "print(\"smog_index: \",ts1.smog_index)\n",
    "print(\"\\n\")\n",
    "#lexical-diversity\n",
    "# https://pypi.org/project/lexical-diversity/\n",
    "flt = ld.flemmatize(output)\n",
    "print(\"no of tokens: \",len(ld.tokenize(output)))\n",
    "print(\"ttr: \",ld.ttr(flt))\n",
    "print(\"root_ttr: \",ld.root_ttr(flt))\n",
    "print(\"log_ttr: \",ld.log_ttr(flt))\n",
    "print(\"maas_ttr: \",ld.maas_ttr(flt))\n",
    "print(\"mtld: \", ld.mtld(flt))\n",
    "print(\"hdd: \", ld.hdd(flt))\n",
    "print(\"msttr: \", ld.msttr(flt,window_length=25))\n",
    "print(\"mattr: \", ld.mattr(flt,window_length=25))\n",
    "print(\"mtld_ma_wrap: \",ld.mtld_ma_wrap(flt))\n",
    "print(\"mtld_ma_bid: \",ld.mtld_ma_bid(flt))\n",
    "\n",
    "\n",
    "# print(ts1.entropy)\n",
    "# print(\"ttr: \",ts1.ttr)\n",
    "#0.7857142857142857\n",
    "#ts2 = ts.readability(doc)\n",
    "\n",
    "#doc._.to_bag_of_words()\n",
    "#print(next(extract.words(doc)))\n",
    "# print(extract.keyterms.textrank(doc))\n",
    "# #preprocessing.remove.punctuation(text, only=[\".\", \"?\", \"!\"])\n",
    "\n",
    "# next(iter(doc)) #tokens\n",
    "# ts.readability\n",
    "# ts.basics\n",
    "#print(np.mean(ts1.n_chars_per_word))\n",
    "\n",
    "# print(np.mean(ts1.n_syllables_per_word))\n",
    "\n",
    "# print(ts1.counts)\n",
    "# #doc.lang_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install textstat\n",
    "text=output1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "syllable_count:               6914\n",
      "lexicon_count:                3996\n",
      "sentence_count:               279\n",
      "char_count:                   21743\n",
      "letter_count:                 21464\n",
      "polysyllabcount:              899\n",
      "monosyllabcount:              2374\n",
      "\n",
      "\n",
      "*********************************************************************************\n",
      "Flesch Reading Ease:          48.5\n",
      "Flesch Kincaid Grade:         10.0\n",
      "Smog Index:                   13.4\n",
      "Coleman Liau Index:           13.27\n",
      "Automated Readability Index:  11.4\n",
      "Dale Chall Readability Score: 6.21\n",
      "Difficult Words:              405\n",
      "Linsear Write Formula:        12.333333333333334\n",
      "Gunning Fog:                  8.11\n",
      "Text Standard:                12th and 13th grade\n",
      "mcalpine_eflaw:               19.9\n",
      "reading_time:                 319.4\n",
      "\n",
      "\n",
      "*********************************************************************************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nsyllable_count:               6834\\nlexicon_count:                3937\\nsentence_count:               278\\nchar_count:                   21471\\nletter_count:                 21193\\npolysyllabcount:              895\\nmonosyllabcount:              2332\\n\\n\\n*********************************************************************************\\nFlesch Reading Ease:          48.6\\nFlesch Kincaid Grade:         10.0\\nSmog Index:                   13.4\\nColeman Liau Index:           13.33\\nAutomated Readability Index:  11.3\\nDale Chall Readability Score: 6.15\\nDifficult Words:              396\\nLinsear Write Formula:        12.166666666666666\\nGunning Fog:                  8.09\\nText Standard:                12th and 13th grade\\nmcalpine_eflaw:               19.7\\nreading_time:                 315.41\\n '"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import textstat  # https://pypi.org/project/textstat/\n",
    "\n",
    "print(\"\\n\")\n",
    "print('syllable_count:               ' + str(textstat.syllable_count(text)))\n",
    "print('lexicon_count:                ' + str(textstat.lexicon_count(text, removepunct=True)))\n",
    "print('sentence_count:               ' + str(textstat.sentence_count(text)))\n",
    "print('char_count:                   ' + str(textstat.char_count(text, ignore_spaces=True)))\n",
    "print('letter_count:                 ' + str(textstat.letter_count(text, ignore_spaces=True)))\n",
    "print('polysyllabcount:              ' + str(textstat.polysyllabcount(text)))\n",
    "print('monosyllabcount:              ' + str(textstat.monosyllabcount(text)))\n",
    "print(\"\\n\")\n",
    "print('*********************************************************************************')\n",
    "#print(\"\\n\")\n",
    "print('Flesch Reading Ease:          ' + str(textstat.flesch_reading_ease(text)))\n",
    "print('Flesch Kincaid Grade:         ' + str(textstat.flesch_kincaid_grade(text)))\n",
    "print('Smog Index:                   ' + str(textstat.smog_index(text)))\n",
    "print('Coleman Liau Index:           ' + str(textstat.coleman_liau_index(text)))\n",
    "print('Automated Readability Index:  ' + str(textstat.automated_readability_index(text)))\n",
    "print('Dale Chall Readability Score: ' + str(textstat.dale_chall_readability_score(text)))\n",
    "print('Difficult Words:              ' + str(textstat.difficult_words(text)))\n",
    "print('Linsear Write Formula:        ' + str(textstat.linsear_write_formula(text)))\n",
    "print('Gunning Fog:                  ' + str(textstat.gunning_fog(text)))\n",
    "print('Text Standard:                ' + str(textstat.text_standard(text)))\n",
    "\n",
    "print('mcalpine_eflaw:               ' + str(textstat.mcalpine_eflaw(text)))\n",
    "print('reading_time:                 ' + str(textstat.reading_time(text, ms_per_char=14.69)))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print('*********************************************************************************')\n",
    "\"\"\"Flesch-Kincaid Grade Level = This is a grade formula in that a score of 9.3 means that a ninth grader would be able to read the document\"\"\"\n",
    "\"\"\"Gunning Fog = This is a grade formula in that a score of 9.3 means that a ninth grader would be able to read the document.\"\"\"\n",
    "\"\"\"SMOG - for 30 sentences or more  =This is a grade formula in that a score of 9.3 means that a ninth grader would be able to read the document.\"\"\"\n",
    "\"\"\"Automated Readability Index = Returns the ARI (Automated Readability Index) which outputs a number that approximates the grade level needed to comprehend the text.\"\"\"\n",
    "\"\"\" Coleman Liau Index = Returns the grade level of the text using the Coleman-Liau Formula.\"\"\"\n",
    "\"\"\"Linsear = Returns the grade level using the Linsear Write Formula.\"\"\"\n",
    "\"\"\" Dale Chall = Different from other tests, since it uses a lookup table of the most commonly used 3000 English words. Thus it returns the grade level using the New Dale-Chall Formula.\"\"\"\n",
    "\"\"\" mcalpine_eflaw = Returns a score for the readability of an english text for a foreign learner or English, focusing on the number of miniwords and length of sentences.\n",
    "It is recommended to aim for a score equal to or lower than 25.\"\"\"\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pypi.org/project/py-readability-metrics/\n",
    "# !pip3 install py-readability-metrics\n",
    "#!python -m nltk.downloader punkt\n",
    "\n",
    "from readability import Readability\n",
    "\n",
    "r = Readability(text)\n",
    "\n",
    "print(\"flesch_kincaid: \", r.flesch_kincaid())\n",
    "# fk = r.flesch_kincaid()\n",
    "# print(fk.score)\n",
    "# print(fk.grade_level)\n",
    "\n",
    "print(\"flesch reading ease: \", r.flesch())\n",
    "# f = r.flesch()\n",
    "# print(f.score)\n",
    "# print(f.ease)\n",
    "# print(f.grade_levels)\n",
    "\n",
    "print(\"gunning_fog: \", r.gunning_fog())\n",
    "# gf = r.gunning_fog()\n",
    "# print(gf.score)\n",
    "# print(gf.grade_level)\n",
    "\n",
    "print(\"coleman_liau: \", r.coleman_liau())\n",
    "# cl = r.coleman_liau()\n",
    "# print(cl.score)\n",
    "# print(cl.grade_level)\n",
    "\n",
    "print(\"dale_chall: \", r.dale_chall())\n",
    "# dc = dale_chall()\n",
    "# print(dc.score)\n",
    "# print(dc.grade_levels)\n",
    "\n",
    "print(\"ari: \", r.ari())\n",
    "# ari = r.ari()\n",
    "# print(ari.score)\n",
    "# print(ari.grade_levels)\n",
    "# print(ari.ages)\n",
    "\n",
    "'''\n",
    "Linsear Write is a readability metric for English text, purportedly developed for the United States Air Force \n",
    "to help them calculate the readability of their technical manuals.\n",
    "'''\n",
    "print(\"linsear_write: \", r.linsear_write()) \n",
    "# lw = r.linsear_write()\n",
    "# print(lw.score)\n",
    "# print(lw.grade_level)\n",
    "\n",
    "'''\n",
    "The SMOG Readability Formula (Simple Measure of Gobbledygook) is a popular method to use on health literacy materials.\n",
    "'''\n",
    "\n",
    "print(\"smog: \", r.smog())\n",
    "# s = r.smog()\n",
    "# print(s.score)\n",
    "# print(s.grade_level)\n",
    "\n",
    "'''The original SMOG formula uses a sample of 30 sentences from the original text. \n",
    "However, the formula can be generalized to any number of sentences. \n",
    "You can use the generalized formula by passing the all_sentences=True argument to smog()'''\n",
    "# s = r.smog(all_sentences=True)\n",
    "# print(s.score)\n",
    "# print(s.grade_level)\n",
    "\n",
    "'''\n",
    "flesch_kincaid:  score: 12.119517006828133, grade_level: '12'\n",
    "flesch reading ease:  score: 32.91425886480454, ease: 'difficult', grade_levels: ['college']\n",
    "gunning_fog:  score: 17.331488965919107, grade_level: 'college_graduate'\n",
    "coleman_liau:  score: 13.80722377444755, grade_level: '14'\n",
    "dale_chall:  score: 10.643150986866681, grade_levels: ['college_graduate']\n",
    "ari:  score: 11.161216681109835, grade_levels: ['12'], ages: [17, 18]\n",
    "linsear_write:  score: 11.413602941176471, grade_level: '11'\n",
    "smog:  score: 15.731716950459138, grade_level: 16\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
